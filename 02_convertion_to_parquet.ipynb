{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = './work/'\n",
    "parquetdir = './parquet/'\n",
    "source_csv = 'votacao_candidato_munzona_2022_BRASIL.csv'\n",
    "extracted_file = workdir +'extracted/'+source_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark_session = SparkSession.builder.appName('spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading file and selecting relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark_session.read.options(header=\"true\", inferSchema=True, delimiter=\";\", encoding=\"ISO-8859-1\").csv(extracted_file)\n",
    "\n",
    "# Defining relevant columns\n",
    "relevant_columns=[\n",
    "    \"NR_TURNO\",\n",
    "    \"DS_ELEICAO\",\n",
    "    \"TP_ABRANGENCIA\",\n",
    "    \"SG_UF\",\n",
    "    \"NM_MUNICIPIO\",\n",
    "    \"NR_ZONA\",\n",
    "    \"DS_CARGO\",\n",
    "    \"NR_CANDIDATO\",\n",
    "    \"NM_CANDIDATO\",\n",
    "    \"NM_URNA_CANDIDATO\",\n",
    "    \"DS_SITUACAO_CANDIDATURA\",\n",
    "    \"NR_PARTIDO\",\n",
    "    \"SG_PARTIDO\",\n",
    "    \"NM_PARTIDO\",\n",
    "    \"NM_COLIGACAO\",\n",
    "    \"DS_COMPOSICAO_COLIGACAO\",\n",
    "    \"ST_VOTO_EM_TRANSITO\",\n",
    "    \"QT_VOTOS_NOMINAIS\",\n",
    "    \"NM_TIPO_DESTINACAO_VOTOS\",\n",
    "    \"QT_VOTOS_NOMINAIS_VALIDOS\",\n",
    "    \"DS_SIT_TOT_TURNO\"\n",
    "]\n",
    "\n",
    "# Selecting relevant columns\n",
    "selected_columns_df = df.select(relevant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing first lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns_df.write.mode(\"overwrite\").options(encoding=\"UTF-8\").parquet(parquetdir + source_csv + \".parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopping spark session\n",
    "spark_session.stop()\n",
    "\n",
    "# Cleaning up files \n",
    "# Delete the directory and all its contents\n",
    "# import shutil\n",
    "\n",
    "# shutil.rmtree(workdir+'extracted/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
